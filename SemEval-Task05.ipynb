{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13856902,"sourceType":"datasetVersion","datasetId":8827385},{"sourceId":13858282,"sourceType":"datasetVersion","datasetId":8828361},{"sourceId":659731,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":498925,"modelId":514176}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"mkdir -p semeval26-05-scripts/input/ref\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:22:54.380473Z","iopub.execute_input":"2025-11-25T00:22:54.380963Z","iopub.status.idle":"2025-11-25T00:22:54.500770Z","shell.execute_reply.started":"2025-11-25T00:22:54.380932Z","shell.execute_reply":"2025-11-25T00:22:54.499525Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"%%writefile semeval26-05-scripts/scoring.py\nimport json\nimport math\nfrom scipy.stats import spearmanr\n\ndef load_jsonl(path):\n    data = {}\n    with open(path, \"r\") as f:\n        for line in f:\n            obj = json.loads(line)\n            data[obj[\"id\"]] = obj\n    return data\n\ndef main(ref_path, pred_path, out_path):\n    ref = load_jsonl(ref_path)\n    pred = load_jsonl(pred_path)\n\n    gold_scores = []\n    pred_scores = []\n    within_std = []\n\n    for _id, gold in ref.items():\n        if _id not in pred:\n            continue\n\n        g = gold[\"mean\"]\n        sd = gold.get(\"std\", 1)\n        p = pred[_id][\"prediction\"]\n\n        gold_scores.append(g)\n        pred_scores.append(p)\n\n        if abs(p - g) <= sd:\n            within_std.append(1)\n        else:\n            within_std.append(0)\n\n    # spearman\n    spearman = spearmanr(gold_scores, pred_scores).correlation\n    if math.isnan(spearman):\n        spearman = 0\n\n    acc = sum(within_std) / len(within_std)\n\n    results = {\n        \"spearman\": float(spearman),\n        \"within_std_accuracy\": float(acc)\n    }\n\n    with open(out_path, \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    print(results)\n\nif __name__ == \"__main__\":\n    import sys\n    main(sys.argv[1], sys.argv[2], sys.argv[3])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:23:01.399776Z","iopub.execute_input":"2025-11-25T00:23:01.400237Z","iopub.status.idle":"2025-11-25T00:23:01.409748Z","shell.execute_reply.started":"2025-11-25T00:23:01.400204Z","shell.execute_reply":"2025-11-25T00:23:01.409032Z"}},"outputs":[{"name":"stdout","text":"Writing semeval26-05-scripts/scoring.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile semeval26-05-scripts/format_check.py\nimport json, sys\n\npath = sys.argv[1]\n\nwith open(path) as f:\n    for i, line in enumerate(f):\n        try:\n            obj = json.loads(line)\n        except:\n            print(\"Line\", i, \"is not valid JSON\")\n            exit(1)\n\n        if \"id\" not in obj:\n            print(\"Missing 'id' at line\", i)\n            exit(1)\n        if \"prediction\" not in obj:\n            print(\"Missing 'prediction' at line\", i)\n            exit(1)\n\nprint(\"Format OK\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:23:13.921220Z","iopub.execute_input":"2025-11-25T00:23:13.921545Z","iopub.status.idle":"2025-11-25T00:23:13.927428Z","shell.execute_reply.started":"2025-11-25T00:23:13.921512Z","shell.execute_reply":"2025-11-25T00:23:13.926568Z"}},"outputs":[{"name":"stdout","text":"Writing semeval26-05-scripts/format_check.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%%writefile generate_solution_from_dev.py\nimport json\n\ndev = json.load(open(\"dev.json\"))\nout = open(\"semeval26-05-scripts/input/ref/solution.jsonl\", \"w\")\n\nfor id_, row in dev.items():\n    obj = {\n        \"id\": id_,\n        \"mean\": float(row[\"mean_score\"]),   # adjust field\n        \"std\": float(row[\"std_score\"]),     # adjust field if exists\n    }\n    out.write(json.dumps(obj) + \"\\n\")\n\nout.close()\nprint(\"Created solution.jsonl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:23:23.147170Z","iopub.execute_input":"2025-11-25T00:23:23.148195Z","iopub.status.idle":"2025-11-25T00:23:23.155005Z","shell.execute_reply.started":"2025-11-25T00:23:23.148151Z","shell.execute_reply":"2025-11-25T00:23:23.153152Z"}},"outputs":[{"name":"stdout","text":"Writing generate_solution_from_dev.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!ls -R /kaggle/working\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:24:20.855078Z","iopub.execute_input":"2025-11-25T00:24:20.855346Z","iopub.status.idle":"2025-11-25T00:24:20.976587Z","shell.execute_reply.started":"2025-11-25T00:24:20.855326Z","shell.execute_reply":"2025-11-25T00:24:20.975466Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working:\ngenerate_solution_from_dev.py  semeval26-05-scripts\n\n/kaggle/working/semeval26-05-scripts:\nformat_check.py  input\tscoring.py\n\n/kaggle/working/semeval26-05-scripts/input:\nref\n\n/kaggle/working/semeval26-05-scripts/input/ref:\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!ls -R /kaggle/input/semeval26-task5-dataa\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:28:37.641991Z","iopub.execute_input":"2025-11-25T00:28:37.642339Z","iopub.status.idle":"2025-11-25T00:28:37.771576Z","shell.execute_reply.started":"2025-11-25T00:28:37.642306Z","shell.execute_reply":"2025-11-25T00:28:37.770753Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/semeval26-task5-dataa:\ndev.json  sample_data.json  train.json\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!mkdir -p /kaggle/working/src\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:31:08.873289Z","iopub.execute_input":"2025-11-25T00:31:08.873610Z","iopub.status.idle":"2025-11-25T00:31:08.992690Z","shell.execute_reply.started":"2025-11-25T00:31:08.873584Z","shell.execute_reply":"2025-11-25T00:31:08.991240Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"%%writefile /kaggle/working/src/dataset.py\nimport json\nfrom datasets import Dataset\n\nLABEL_FIELD = \"average\"\nSTD_FIELD = \"stdev\"\n\nTEXT_FIELDS = [\n    \"precontext\",\n    \"sentence\",\n    \"ending\",\n    \"example_sentence\",\n    \"judged_meaning\",\n    \"homonym\"\n]\n\ndef _normalize(path):\n    data = json.load(open(path, \"r\"))\n    samples = []\n\n    if isinstance(data, dict):\n        for k, ex in data.items():\n            ex = dict(ex)\n            ex[\"id\"] = str(k)\n            samples.append(ex)\n    else:\n        for i, ex in enumerate(data):\n            ex = dict(ex)\n            ex.setdefault(\"id\", str(i))\n            samples.append(ex)\n\n    return samples\n\n\ndef _build_text(ex):\n    parts = []\n    for field in TEXT_FIELDS:\n        if field in ex and isinstance(ex[field], str):\n            parts.append(ex[field])\n    return \" \".join(parts)\n\n\ndef load_dataset(path):\n    raw = _normalize(path)\n    processed = []\n\n    for ex in raw:\n        row = {\n            \"id\": ex[\"id\"],\n            \"text\": _build_text(ex),\n        }\n        if LABEL_FIELD in ex:\n            row[LABEL_FIELD] = float(ex[LABEL_FIELD])\n        if STD_FIELD in ex:\n            row[STD_FIELD] = float(ex[STD_FIELD])\n        processed.append(row)\n\n    return Dataset.from_list(processed)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:31:17.907416Z","iopub.execute_input":"2025-11-25T00:31:17.907753Z","iopub.status.idle":"2025-11-25T00:31:17.914417Z","shell.execute_reply.started":"2025-11-25T00:31:17.907729Z","shell.execute_reply":"2025-11-25T00:31:17.913384Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/src/dataset.py\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"%%writefile /kaggle/working/generate_solution_from_dev.py\nimport json\n\ndev = json.load(open(\"/kaggle/input/semeval26-task5-dataa/dev.json\"))\nout = open(\"/kaggle/working/semeval26-05-scripts/input/ref/solution.jsonl\", \"w\")\n\nfor _id, row in dev.items():\n    obj = {\n        \"id\": str(_id),\n        \"mean\": float(row[\"average\"]),\n        \"std\": float(row[\"stdev\"])\n    }\n    out.write(json.dumps(obj) + \"\\n\")\n\nout.close()\nprint(\"Created solution.jsonl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:31:26.843181Z","iopub.execute_input":"2025-11-25T00:31:26.843442Z","iopub.status.idle":"2025-11-25T00:31:26.849180Z","shell.execute_reply.started":"2025-11-25T00:31:26.843421Z","shell.execute_reply":"2025-11-25T00:31:26.847855Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/generate_solution_from_dev.py\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!python /kaggle/working/generate_solution_from_dev.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:31:32.752441Z","iopub.execute_input":"2025-11-25T00:31:32.752778Z","iopub.status.idle":"2025-11-25T00:31:32.966512Z","shell.execute_reply.started":"2025-11-25T00:31:32.752762Z","shell.execute_reply":"2025-11-25T00:31:32.965688Z"}},"outputs":[{"name":"stdout","text":"Created solution.jsonl\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!ls /kaggle/input\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:44:43.327146Z","iopub.execute_input":"2025-11-25T00:44:43.327461Z","iopub.status.idle":"2025-11-25T00:44:43.447617Z","shell.execute_reply.started":"2025-11-25T00:44:43.327434Z","shell.execute_reply":"2025-11-25T00:44:43.446342Z"}},"outputs":[{"name":"stdout","text":"roberta-base-model  semeval26-task5-dataa\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"!ls -R /kaggle/input/roberta-base-model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:45:19.537178Z","iopub.execute_input":"2025-11-25T00:45:19.537452Z","iopub.status.idle":"2025-11-25T00:45:19.660182Z","shell.execute_reply.started":"2025-11-25T00:45:19.537431Z","shell.execute_reply":"2025-11-25T00:45:19.659121Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/roberta-base-model:\nother\n\n/kaggle/input/roberta-base-model/other:\ndefault\n\n/kaggle/input/roberta-base-model/other/default:\n1\n\n/kaggle/input/roberta-base-model/other/default/1:\nroberta-base\n\n/kaggle/input/roberta-base-model/other/default/1/roberta-base:\nconfig.json  model.safetensors\t      tokenizer_config.json  vocab.json\nmerges.txt   special_tokens_map.json  tokenizer.json\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"%%writefile /kaggle/working/src/train_model.py\nimport os\nimport numpy as np\nfrom transformers import (\n    AutoTokenizer, AutoModelForSequenceClassification,\n    TrainingArguments, Trainer\n)\nfrom scipy.stats import spearmanr\nfrom datasets import DatasetDict\nfrom dataset import load_dataset, LABEL_FIELD\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# Your offline model path (correct)\nMODEL_NAME = \"/kaggle/input/roberta-base-model/other/default/1/roberta-base\"\n\nOUT_DIR = \"/kaggle/working/models/semeval_roberta\"\nMAX_LEN = 256\n\n\ndef tokenize(batch, tokenizer):\n    enc = tokenizer(\n        batch[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=MAX_LEN\n    )\n    enc[\"labels\"] = batch[LABEL_FIELD]\n    return enc\n\n\ndef compute_metrics(eval_pred):\n    preds, labels = eval_pred\n    preds = preds[:, 0] if preds.ndim > 1 else preds\n    preds = np.clip(np.rint(preds), 1, 5)\n    s = spearmanr(preds, labels).correlation\n    return {\"spearman\": float(0 if np.isnan(s) else s)}\n\n\ndef main():\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\n    train = load_dataset(\"/kaggle/input/semeval26-task5-dataa/train.json\")\n    dev = load_dataset(\"/kaggle/input/semeval26-task5-dataa/dev.json\")\n\n    tokenized = DatasetDict({\n        \"train\": train.map(lambda b: tokenize(b, tokenizer), batched=True),\n        \"dev\": dev.map(lambda b: tokenize(b, tokenizer), batched=True)\n    })\n\n    # Load model but ignore mismatched classifier weights\n    model = AutoModelForSequenceClassification.from_pretrained(\n        MODEL_NAME,\n        num_labels=1,\n        problem_type=\"regression\",\n        ignore_mismatched_sizes=True\n    )\n\n    # Kaggle-safe TrainingArguments (older transformers compatible)\n    args = TrainingArguments(\n        output_dir=OUT_DIR,\n        do_train=True,\n        do_eval=True,\n        learning_rate=2e-5,\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        num_train_epochs=3,\n        weight_decay=0.01,\n        logging_steps=100,\n        save_steps=500,\n        report_to=[]  # disable WandB\n    )\n\n    trainer = Trainer(\n        model=model,\n        tokenizer=tokenizer,\n        args=args,\n        train_dataset=tokenized[\"train\"],\n        eval_dataset=tokenized[\"dev\"],\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n    trainer.save_model(OUT_DIR)\n    tokenizer.save_pretrained(OUT_DIR)\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:49:41.768314Z","iopub.execute_input":"2025-11-25T00:49:41.768627Z","iopub.status.idle":"2025-11-25T00:49:41.775183Z","shell.execute_reply.started":"2025-11-25T00:49:41.768600Z","shell.execute_reply":"2025-11-25T00:49:41.774222Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/src/train_model.py\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"!python /kaggle/working/src/train_model.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T00:52:02.506840Z","iopub.execute_input":"2025-11-25T00:52:02.507158Z","iopub.status.idle":"2025-11-25T03:02:04.865136Z","shell.execute_reply.started":"2025-11-25T00:52:02.507120Z","shell.execute_reply":"2025-11-25T03:02:04.863369Z"}},"outputs":[{"name":"stdout","text":"2025-11-25 00:52:07.827095: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764031927.844600     189 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764031927.849577     189 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nMap: 100%|█████████████████████████| 2280/2280 [00:00<00:00, 3934.29 examples/s]\nMap: 100%|███████████████████████████| 588/588 [00:00<00:00, 3646.71 examples/s]\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/roberta-base-model/other/default/1/roberta-base and are newly initialized because the shapes did not match:\n- classifier.out_proj.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([1]) in the model instantiated\n- classifier.out_proj.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([1, 768]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/kaggle/working/src/train_model.py:73: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n{'loss': 2.2938, 'grad_norm': 6.382079124450684, 'learning_rate': 1.768421052631579e-05, 'epoch': 0.35}\n{'loss': 1.507, 'grad_norm': 20.587974548339844, 'learning_rate': 1.534502923976608e-05, 'epoch': 0.7}\n{'loss': 1.274, 'grad_norm': 30.75804328918457, 'learning_rate': 1.3005847953216374e-05, 'epoch': 1.05}\n{'loss': 1.2053, 'grad_norm': 19.89206886291504, 'learning_rate': 1.0666666666666667e-05, 'epoch': 1.4}\n{'loss': 1.0139, 'grad_norm': 22.545764923095703, 'learning_rate': 8.32748538011696e-06, 'epoch': 1.75}\n{'loss': 0.9726, 'grad_norm': 28.183427810668945, 'learning_rate': 5.988304093567252e-06, 'epoch': 2.11}\n{'loss': 0.7444, 'grad_norm': 63.50493621826172, 'learning_rate': 3.6491228070175443e-06, 'epoch': 2.46}\n{'loss': 0.6465, 'grad_norm': 87.28376007080078, 'learning_rate': 1.3099415204678364e-06, 'epoch': 2.81}\n{'train_runtime': 7785.1898, 'train_samples_per_second': 0.879, 'train_steps_per_second': 0.11, 'train_loss': 1.1743897555167215, 'epoch': 3.0}\n100%|███████████████████████████████████████| 855/855 [2:09:45<00:00,  9.11s/it]\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"%%writefile /kaggle/working/src/generate_solution_from_dev.py\nimport json\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom dataset import load_dataset, LABEL_FIELD\nimport torch\n\nMODEL_PATH = \"/kaggle/working/models/semeval_roberta\"   # path after training\nDEV_PATH = \"/kaggle/input/semeval26-task5-dataa/dev.json\"\nOUT_FILE = \"/kaggle/working/predictions_dev.jsonl\"\n\ndef main():\n    print(\"Loading model...\")\n    model = AutoModelForSequenceClassification.from_pretrained(\n        MODEL_PATH, num_labels=1, problem_type=\"regression\"\n    )\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\n    print(\"Loading dev set...\")\n    dev = load_dataset(DEV_PATH)\n\n    preds = []\n\n    print(\"Generating predictions...\")\n    for ex in dev:\n        inputs = tokenizer(\n            ex[\"text\"],\n            truncation=True,\n            padding=True,\n            max_length=256,\n            return_tensors=\"pt\"\n        )\n\n        with torch.no_grad():\n            output = model(**inputs)\n            score = output.logits.squeeze().item()\n\n        # Clip + round to valid SemEval range 1–5\n        score = float(np.clip(round(score), 1, 5))\n\n        preds.append({\"id\": ex[\"id\"], \"pred\": score})\n\n    print(f\"Writing to {OUT_FILE} ...\")\n    with open(OUT_FILE, \"w\") as f:\n        for p in preds:\n            f.write(json.dumps(p) + \"\\n\")\n\n    print(\"Done! File saved:\", OUT_FILE)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:04:08.890227Z","iopub.execute_input":"2025-11-25T03:04:08.891230Z","iopub.status.idle":"2025-11-25T03:04:08.901612Z","shell.execute_reply.started":"2025-11-25T03:04:08.891177Z","shell.execute_reply":"2025-11-25T03:04:08.899961Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/src/generate_solution_from_dev.py\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"!python /kaggle/working/src/generate_solution_from_dev.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:04:16.207916Z","iopub.execute_input":"2025-11-25T03:04:16.208202Z","iopub.status.idle":"2025-11-25T03:06:22.346705Z","shell.execute_reply.started":"2025-11-25T03:04:16.208186Z","shell.execute_reply":"2025-11-25T03:06:22.345756Z"}},"outputs":[{"name":"stdout","text":"Loading model...\n2025-11-25 03:04:26.748261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764039866.805306     211 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764039866.823948     211 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nLoading dev set...\nGenerating predictions...\nWriting to /kaggle/working/predictions_dev.jsonl ...\nDone! File saved: /kaggle/working/predictions_dev.jsonl\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import json\nfrom pprint import pprint\n\nwith open(\"/kaggle/input/semeval26-task5-dataa/dev.json\") as f:\n    dev = json.load(f)\n\nfirst = list(dev.items())[0]\npprint(first)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:09:28.591245Z","iopub.execute_input":"2025-11-25T03:09:28.591701Z","iopub.status.idle":"2025-11-25T03:09:28.606010Z","shell.execute_reply.started":"2025-11-25T03:09:28.591660Z","shell.execute_reply":"2025-11-25T03:09:28.605029Z"}},"outputs":[{"name":"stdout","text":"('0',\n {'average': 3.6,\n  'choices': [4, 5, 3, 1, 5],\n  'ending': 'They began to run along the abandoned railway line, hopping from '\n            'wooden sleeper to sleeper to avoid twisting an ankle.',\n  'example_sentence': 'The train glided smoothly along the track.',\n  'homonym': 'track',\n  'judged_meaning': 'a pair of parallel rails providing a runway for wheels',\n  'nonsensical': [False, False, False, False, False],\n  'precontext': 'The detectives arrived at the abandoned train station. They '\n                'were looking for signs of the missing artifact. A faint trail '\n                'caught their attention.',\n  'sample_id': '2371',\n  'sentence': 'They followed the track.',\n  'stdev': 1.6733200530681511})\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"!head -n 20 /kaggle/working/predictions_dev.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:09:59.872893Z","iopub.execute_input":"2025-11-25T03:09:59.873209Z","iopub.status.idle":"2025-11-25T03:09:59.995944Z","shell.execute_reply.started":"2025-11-25T03:09:59.873191Z","shell.execute_reply":"2025-11-25T03:09:59.994282Z"}},"outputs":[{"name":"stdout","text":"{\"id\": \"0\", \"pred\": 4.0}\n{\"id\": \"1\", \"pred\": 3.0}\n{\"id\": \"2\", \"pred\": 3.0}\n{\"id\": \"3\", \"pred\": 4.0}\n{\"id\": \"4\", \"pred\": 3.0}\n{\"id\": \"5\", \"pred\": 3.0}\n{\"id\": \"6\", \"pred\": 5.0}\n{\"id\": \"7\", \"pred\": 3.0}\n{\"id\": \"8\", \"pred\": 5.0}\n{\"id\": \"9\", \"pred\": 5.0}\n{\"id\": \"10\", \"pred\": 4.0}\n{\"id\": \"11\", \"pred\": 4.0}\n{\"id\": \"12\", \"pred\": 4.0}\n{\"id\": \"13\", \"pred\": 4.0}\n{\"id\": \"14\", \"pred\": 4.0}\n{\"id\": \"15\", \"pred\": 4.0}\n{\"id\": \"16\", \"pred\": 4.0}\n{\"id\": \"17\", \"pred\": 4.0}\n{\"id\": \"18\", \"pred\": 5.0}\n{\"id\": \"19\", \"pred\": 4.0}\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"%%writefile /kaggle/working/src/fix_predictions.py\nimport json\n\ninput_path = \"/kaggle/working/predictions_dev.jsonl\"\noutput_path = \"/kaggle/working/predictions_dev_fixed.jsonl\"\n\nwith open(input_path, \"r\") as fin, open(output_path, \"w\") as fout:\n    for line in fin:\n        obj = json.loads(line)\n        # extract score, rename field\n        score = float(obj[\"pred\"])\n        fout.write(json.dumps({\"prediction\": score}) + \"\\n\")\n\nprint(\"Fixed file saved to:\", output_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:10:19.426477Z","iopub.execute_input":"2025-11-25T03:10:19.426798Z","iopub.status.idle":"2025-11-25T03:10:19.434647Z","shell.execute_reply.started":"2025-11-25T03:10:19.426774Z","shell.execute_reply":"2025-11-25T03:10:19.432771Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/src/fix_predictions.py\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"!python /kaggle/working/src/fix_predictions.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:10:26.892920Z","iopub.execute_input":"2025-11-25T03:10:26.893233Z","iopub.status.idle":"2025-11-25T03:10:27.098577Z","shell.execute_reply.started":"2025-11-25T03:10:26.893212Z","shell.execute_reply":"2025-11-25T03:10:27.096818Z"}},"outputs":[{"name":"stdout","text":"Fixed file saved to: /kaggle/working/predictions_dev_fixed.jsonl\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"!head -n 20 /kaggle/working/predictions_dev_fixed.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:10:37.094600Z","iopub.execute_input":"2025-11-25T03:10:37.094937Z","iopub.status.idle":"2025-11-25T03:10:37.216178Z","shell.execute_reply.started":"2025-11-25T03:10:37.094914Z","shell.execute_reply":"2025-11-25T03:10:37.214757Z"}},"outputs":[{"name":"stdout","text":"{\"prediction\": 4.0}\n{\"prediction\": 3.0}\n{\"prediction\": 3.0}\n{\"prediction\": 4.0}\n{\"prediction\": 3.0}\n{\"prediction\": 3.0}\n{\"prediction\": 5.0}\n{\"prediction\": 3.0}\n{\"prediction\": 5.0}\n{\"prediction\": 5.0}\n{\"prediction\": 4.0}\n{\"prediction\": 4.0}\n{\"prediction\": 4.0}\n{\"prediction\": 4.0}\n{\"prediction\": 4.0}\n{\"prediction\": 4.0}\n{\"prediction\": 4.0}\n{\"prediction\": 4.0}\n{\"prediction\": 5.0}\n{\"prediction\": 4.0}\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"!ls -l /kaggle/working/semeval26-05-scripts/input/ref/solution.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:14:39.406818Z","iopub.execute_input":"2025-11-25T03:14:39.407162Z","iopub.status.idle":"2025-11-25T03:14:39.530545Z","shell.execute_reply.started":"2025-11-25T03:14:39.407136Z","shell.execute_reply":"2025-11-25T03:14:39.528623Z"}},"outputs":[{"name":"stdout","text":"-rw-r--r-- 1 root root 30597 Nov 25 00:31 /kaggle/working/semeval26-05-scripts/input/ref/solution.jsonl\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"!head -n 20 /kaggle/working/semeval26-05-scripts/input/ref/solution.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:15:05.162623Z","iopub.execute_input":"2025-11-25T03:15:05.162968Z","iopub.status.idle":"2025-11-25T03:15:05.295008Z","shell.execute_reply.started":"2025-11-25T03:15:05.162940Z","shell.execute_reply":"2025-11-25T03:15:05.293561Z"}},"outputs":[{"name":"stdout","text":"{\"id\": \"0\", \"mean\": 3.6, \"std\": 1.6733200530681511}\n{\"id\": \"1\", \"mean\": 3.6, \"std\": 0.5477225575051661}\n{\"id\": \"2\", \"mean\": 3.8, \"std\": 1.3038404810405297}\n{\"id\": \"3\", \"mean\": 4.2, \"std\": 0.8366600265340756}\n{\"id\": \"4\", \"mean\": 3.0, \"std\": 1.8708286933869707}\n{\"id\": \"5\", \"mean\": 3.0, \"std\": 1.224744871391589}\n{\"id\": \"6\", \"mean\": 4.6, \"std\": 0.5477225575051661}\n{\"id\": \"7\", \"mean\": 1.3333333333333333, \"std\": 0.5163977794943223}\n{\"id\": \"8\", \"mean\": 2.2, \"std\": 1.3038404810405297}\n{\"id\": \"9\", \"mean\": 3.8, \"std\": 1.0954451150103321}\n{\"id\": \"10\", \"mean\": 3.2, \"std\": 1.4832396974191326}\n{\"id\": \"11\", \"mean\": 2.2, \"std\": 1.6431676725154984}\n{\"id\": \"12\", \"mean\": 4.0, \"std\": 1.0}\n{\"id\": \"13\", \"mean\": 3.0, \"std\": 1.5811388300841898}\n{\"id\": \"14\", \"mean\": 2.2, \"std\": 0.8366600265340756}\n{\"id\": \"15\", \"mean\": 2.4, \"std\": 1.140175425099138}\n{\"id\": \"16\", \"mean\": 3.4, \"std\": 1.816590212458495}\n{\"id\": \"17\", \"mean\": 2.0, \"std\": 0.8944271909999159}\n{\"id\": \"18\", \"mean\": 4.6, \"std\": 0.8944271909999159}\n{\"id\": \"19\", \"mean\": 1.2, \"std\": 0.4472135954999579}\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"!sed -n '1p' /kaggle/working/predictions_dev_fixed.jsonl | od -c\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:16:03.349870Z","iopub.execute_input":"2025-11-25T03:16:03.350212Z","iopub.status.idle":"2025-11-25T03:16:03.486049Z","shell.execute_reply.started":"2025-11-25T03:16:03.350185Z","shell.execute_reply":"2025-11-25T03:16:03.484446Z"}},"outputs":[{"name":"stdout","text":"0000000   {   \"   p   r   e   d   i   c   t   i   o   n   \"   :       4\n0000020   .   0   }  \\n\n0000024\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"!ls -R /kaggle/working/semeval26-05-scripts\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:18:47.174427Z","iopub.execute_input":"2025-11-25T03:18:47.174838Z","iopub.status.idle":"2025-11-25T03:18:47.298667Z","shell.execute_reply.started":"2025-11-25T03:18:47.174810Z","shell.execute_reply":"2025-11-25T03:18:47.297180Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/semeval26-05-scripts:\nformat_check.py  input\tscoring.py\n\n/kaggle/working/semeval26-05-scripts/input:\nref\n\n/kaggle/working/semeval26-05-scripts/input/ref:\nsolution.jsonl\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"!sed -n '1,50p' /kaggle/working/semeval26-05-scripts/input/ref/solution.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:19:43.994152Z","iopub.execute_input":"2025-11-25T03:19:43.994420Z","iopub.status.idle":"2025-11-25T03:19:44.117605Z","shell.execute_reply.started":"2025-11-25T03:19:43.994401Z","shell.execute_reply":"2025-11-25T03:19:44.115205Z"}},"outputs":[{"name":"stdout","text":"{\"id\": \"0\", \"mean\": 3.6, \"std\": 1.6733200530681511}\n{\"id\": \"1\", \"mean\": 3.6, \"std\": 0.5477225575051661}\n{\"id\": \"2\", \"mean\": 3.8, \"std\": 1.3038404810405297}\n{\"id\": \"3\", \"mean\": 4.2, \"std\": 0.8366600265340756}\n{\"id\": \"4\", \"mean\": 3.0, \"std\": 1.8708286933869707}\n{\"id\": \"5\", \"mean\": 3.0, \"std\": 1.224744871391589}\n{\"id\": \"6\", \"mean\": 4.6, \"std\": 0.5477225575051661}\n{\"id\": \"7\", \"mean\": 1.3333333333333333, \"std\": 0.5163977794943223}\n{\"id\": \"8\", \"mean\": 2.2, \"std\": 1.3038404810405297}\n{\"id\": \"9\", \"mean\": 3.8, \"std\": 1.0954451150103321}\n{\"id\": \"10\", \"mean\": 3.2, \"std\": 1.4832396974191326}\n{\"id\": \"11\", \"mean\": 2.2, \"std\": 1.6431676725154984}\n{\"id\": \"12\", \"mean\": 4.0, \"std\": 1.0}\n{\"id\": \"13\", \"mean\": 3.0, \"std\": 1.5811388300841898}\n{\"id\": \"14\", \"mean\": 2.2, \"std\": 0.8366600265340756}\n{\"id\": \"15\", \"mean\": 2.4, \"std\": 1.140175425099138}\n{\"id\": \"16\", \"mean\": 3.4, \"std\": 1.816590212458495}\n{\"id\": \"17\", \"mean\": 2.0, \"std\": 0.8944271909999159}\n{\"id\": \"18\", \"mean\": 4.6, \"std\": 0.8944271909999159}\n{\"id\": \"19\", \"mean\": 1.2, \"std\": 0.4472135954999579}\n{\"id\": \"20\", \"mean\": 2.2, \"std\": 1.6431676725154984}\n{\"id\": \"21\", \"mean\": 4.8, \"std\": 0.4472135954999579}\n{\"id\": \"22\", \"mean\": 3.2, \"std\": 0.8366600265340756}\n{\"id\": \"23\", \"mean\": 3.0, \"std\": 1.4142135623730951}\n{\"id\": \"24\", \"mean\": 2.4, \"std\": 1.6733200530681511}\n{\"id\": \"25\", \"mean\": 2.6, \"std\": 1.816590212458495}\n{\"id\": \"26\", \"mean\": 3.8, \"std\": 1.6431676725154984}\n{\"id\": \"27\", \"mean\": 1.8, \"std\": 1.3038404810405297}\n{\"id\": \"28\", \"mean\": 3.0, \"std\": 1.5811388300841898}\n{\"id\": \"29\", \"mean\": 2.8, \"std\": 1.0954451150103321}\n{\"id\": \"30\", \"mean\": 4.4, \"std\": 0.5477225575051661}\n{\"id\": \"31\", \"mean\": 2.0, \"std\": 1.7320508075688772}\n{\"id\": \"32\", \"mean\": 4.6, \"std\": 0.8944271909999159}\n{\"id\": \"33\", \"mean\": 2.4, \"std\": 1.6733200530681511}\n{\"id\": \"34\", \"mean\": 4.8, \"std\": 0.4472135954999579}\n{\"id\": \"35\", \"mean\": 2.8, \"std\": 1.6431676725154984}\n{\"id\": \"36\", \"mean\": 4.4, \"std\": 0.5477225575051661}\n{\"id\": \"37\", \"mean\": 1.2, \"std\": 0.4472135954999579}\n{\"id\": \"38\", \"mean\": 3.8, \"std\": 1.7888543819998317}\n{\"id\": \"39\", \"mean\": 1.8, \"std\": 0.8366600265340756}\n{\"id\": \"40\", \"mean\": 4.4, \"std\": 0.8944271909999159}\n{\"id\": \"41\", \"mean\": 1.6, \"std\": 1.3416407864998738}\n{\"id\": \"42\", \"mean\": 1.8, \"std\": 0.8366600265340756}\n{\"id\": \"43\", \"mean\": 2.4, \"std\": 1.6733200530681511}\n{\"id\": \"44\", \"mean\": 1.2, \"std\": 0.4472135954999579}\n{\"id\": \"45\", \"mean\": 5.0, \"std\": 0.0}\n{\"id\": \"46\", \"mean\": 2.0, \"std\": 1.4142135623730951}\n{\"id\": \"47\", \"mean\": 3.4, \"std\": 1.51657508881031}\n{\"id\": \"48\", \"mean\": 5.0, \"std\": 0.0}\n{\"id\": \"49\", \"mean\": 1.0, \"std\": 0.0}\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"%%writefile /kaggle/working/fix_reference.py\nimport json\nimport numpy as np\n\ninput_path = \"/mnt/data/solution.jsonl\"\noutput_path = \"/kaggle/working/solution.jsonl\"\n\nwith open(input_path) as fin, open(output_path, \"w\") as fout:\n    for line in fin:\n        obj = json.loads(line)\n        labels = obj[\"label\"]\n        mean = float(np.mean(labels))\n        std = float(np.std(labels, ddof=0))\n        fout.write(json.dumps({\n            \"id\": obj[\"id\"],\n            \"mean\": mean,\n            \"std\": std\n        }) + \"\\n\")\n\nprint(\"Corrected reference file written to:\", output_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:22:34.440866Z","iopub.execute_input":"2025-11-25T03:22:34.441194Z","iopub.status.idle":"2025-11-25T03:22:34.447149Z","shell.execute_reply.started":"2025-11-25T03:22:34.441170Z","shell.execute_reply":"2025-11-25T03:22:34.446527Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/fix_reference.py\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"!sed -n '1,30p' /kaggle/input/solution-fixed/solution_fixed.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:33:26.309983Z","iopub.execute_input":"2025-11-25T03:33:26.310383Z","iopub.status.idle":"2025-11-25T03:33:26.446151Z","shell.execute_reply.started":"2025-11-25T03:33:26.310352Z","shell.execute_reply":"2025-11-25T03:33:26.444228Z"}},"outputs":[{"name":"stdout","text":"{\"id\": \"0\", \"mean\": 3.6, \"std\": 1.4966629547095764}\n{\"id\": \"1\", \"mean\": 3.6, \"std\": 0.4898979485566356}\n{\"id\": \"2\", \"mean\": 3.8, \"std\": 1.16619037896906}\n{\"id\": \"3\", \"mean\": 4.2, \"std\": 0.7483314773547882}\n{\"id\": \"4\", \"mean\": 3.0, \"std\": 1.6733200530681511}\n{\"id\": \"5\", \"mean\": 3.0, \"std\": 1.0954451150103321}\n{\"id\": \"6\", \"mean\": 4.6, \"std\": 0.48989794855663565}\n{\"id\": \"7\", \"mean\": 1.3333333333333333, \"std\": 0.4714045207910317}\n{\"id\": \"8\", \"mean\": 2.2, \"std\": 1.16619037896906}\n{\"id\": \"9\", \"mean\": 3.8, \"std\": 0.9797958971132712}\n{\"id\": \"10\", \"mean\": 3.2, \"std\": 1.32664991614216}\n{\"id\": \"11\", \"mean\": 2.2, \"std\": 1.469693845669907}\n{\"id\": \"12\", \"mean\": 4.0, \"std\": 0.8944271909999159}\n{\"id\": \"13\", \"mean\": 3.0, \"std\": 1.4142135623730951}\n{\"id\": \"14\", \"mean\": 2.2, \"std\": 0.7483314773547882}\n{\"id\": \"15\", \"mean\": 2.4, \"std\": 1.019803902718557}\n{\"id\": \"16\", \"mean\": 3.4, \"std\": 1.624807680927192}\n{\"id\": \"17\", \"mean\": 2.0, \"std\": 0.816496580927726}\n{\"id\": \"18\", \"mean\": 4.6, \"std\": 0.7999999999999999}\n{\"id\": \"19\", \"mean\": 1.2, \"std\": 0.4000000000000001}\n{\"id\": \"20\", \"mean\": 2.2, \"std\": 1.469693845669907}\n{\"id\": \"21\", \"mean\": 4.8, \"std\": 0.39999999999999997}\n{\"id\": \"22\", \"mean\": 3.2, \"std\": 0.7483314773547882}\n{\"id\": \"23\", \"mean\": 3.0, \"std\": 1.2649110640673518}\n{\"id\": \"24\", \"mean\": 2.4, \"std\": 1.4966629547095764}\n{\"id\": \"25\", \"mean\": 2.6, \"std\": 1.624807680927192}\n{\"id\": \"26\", \"mean\": 3.8, \"std\": 1.469693845669907}\n{\"id\": \"27\", \"mean\": 1.8, \"std\": 1.1661903789690602}\n{\"id\": \"28\", \"mean\": 3.0, \"std\": 1.4142135623730951}\n{\"id\": \"29\", \"mean\": 2.8, \"std\": 0.9797958971132712}\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"!ls /kaggle/input\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:34:14.115148Z","iopub.execute_input":"2025-11-25T03:34:14.115564Z","iopub.status.idle":"2025-11-25T03:34:14.236627Z","shell.execute_reply.started":"2025-11-25T03:34:14.115530Z","shell.execute_reply":"2025-11-25T03:34:14.235078Z"}},"outputs":[{"name":"stdout","text":"roberta-base-model  semeval26-task5-dataa  solution-fixed\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"!ls -R /kaggle/input/solution-fixed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:34:46.362615Z","iopub.execute_input":"2025-11-25T03:34:46.363444Z","iopub.status.idle":"2025-11-25T03:34:46.490609Z","shell.execute_reply.started":"2025-11-25T03:34:46.363418Z","shell.execute_reply":"2025-11-25T03:34:46.489262Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/solution-fixed:\nsolution_fixed.jsonl\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"!sed -n '1,20p' /kaggle/input/solution-fixed/solution_fixed.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:35:12.353587Z","iopub.execute_input":"2025-11-25T03:35:12.354002Z","iopub.status.idle":"2025-11-25T03:35:12.482549Z","shell.execute_reply.started":"2025-11-25T03:35:12.353969Z","shell.execute_reply":"2025-11-25T03:35:12.480990Z"}},"outputs":[{"name":"stdout","text":"{\"id\": \"0\", \"mean\": 3.6, \"std\": 1.4966629547095764}\n{\"id\": \"1\", \"mean\": 3.6, \"std\": 0.4898979485566356}\n{\"id\": \"2\", \"mean\": 3.8, \"std\": 1.16619037896906}\n{\"id\": \"3\", \"mean\": 4.2, \"std\": 0.7483314773547882}\n{\"id\": \"4\", \"mean\": 3.0, \"std\": 1.6733200530681511}\n{\"id\": \"5\", \"mean\": 3.0, \"std\": 1.0954451150103321}\n{\"id\": \"6\", \"mean\": 4.6, \"std\": 0.48989794855663565}\n{\"id\": \"7\", \"mean\": 1.3333333333333333, \"std\": 0.4714045207910317}\n{\"id\": \"8\", \"mean\": 2.2, \"std\": 1.16619037896906}\n{\"id\": \"9\", \"mean\": 3.8, \"std\": 0.9797958971132712}\n{\"id\": \"10\", \"mean\": 3.2, \"std\": 1.32664991614216}\n{\"id\": \"11\", \"mean\": 2.2, \"std\": 1.469693845669907}\n{\"id\": \"12\", \"mean\": 4.0, \"std\": 0.8944271909999159}\n{\"id\": \"13\", \"mean\": 3.0, \"std\": 1.4142135623730951}\n{\"id\": \"14\", \"mean\": 2.2, \"std\": 0.7483314773547882}\n{\"id\": \"15\", \"mean\": 2.4, \"std\": 1.019803902718557}\n{\"id\": \"16\", \"mean\": 3.4, \"std\": 1.624807680927192}\n{\"id\": \"17\", \"mean\": 2.0, \"std\": 0.816496580927726}\n{\"id\": \"18\", \"mean\": 4.6, \"std\": 0.7999999999999999}\n{\"id\": \"19\", \"mean\": 1.2, \"std\": 0.4000000000000001}\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"!head /kaggle/working/predictions_dev_fixed.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:36:48.464827Z","iopub.execute_input":"2025-11-25T03:36:48.465104Z","iopub.status.idle":"2025-11-25T03:36:48.589159Z","shell.execute_reply.started":"2025-11-25T03:36:48.465085Z","shell.execute_reply":"2025-11-25T03:36:48.586071Z"}},"outputs":[{"name":"stdout","text":"{\"prediction\": 4.0}\n{\"prediction\": 3.0}\n{\"prediction\": 3.0}\n{\"prediction\": 4.0}\n{\"prediction\": 3.0}\n{\"prediction\": 3.0}\n{\"prediction\": 5.0}\n{\"prediction\": 3.0}\n{\"prediction\": 5.0}\n{\"prediction\": 5.0}\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"import json\n\ninp = \"/kaggle/working/predictions_dev_fixed.jsonl\"\nout = \"/kaggle/working/predictions_dev_fixed_with_id.jsonl\"\n\nwith open(inp) as fin, open(out, \"w\") as fout:\n    for i, line in enumerate(fin):\n        obj = json.loads(line)\n        obj[\"id\"] = str(i)     # assign id matching reference\n        fout.write(json.dumps(obj) + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:37:11.780287Z","iopub.execute_input":"2025-11-25T03:37:11.780614Z","iopub.status.idle":"2025-11-25T03:37:11.795934Z","shell.execute_reply.started":"2025-11-25T03:37:11.780593Z","shell.execute_reply":"2025-11-25T03:37:11.793827Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"!head /kaggle/working/predictions_dev_fixed_with_id.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:37:43.013033Z","iopub.execute_input":"2025-11-25T03:37:43.013407Z","iopub.status.idle":"2025-11-25T03:37:43.136214Z","shell.execute_reply.started":"2025-11-25T03:37:43.013377Z","shell.execute_reply":"2025-11-25T03:37:43.134904Z"}},"outputs":[{"name":"stdout","text":"{\"prediction\": 4.0, \"id\": \"0\"}\n{\"prediction\": 3.0, \"id\": \"1\"}\n{\"prediction\": 3.0, \"id\": \"2\"}\n{\"prediction\": 4.0, \"id\": \"3\"}\n{\"prediction\": 3.0, \"id\": \"4\"}\n{\"prediction\": 3.0, \"id\": \"5\"}\n{\"prediction\": 5.0, \"id\": \"6\"}\n{\"prediction\": 3.0, \"id\": \"7\"}\n{\"prediction\": 5.0, \"id\": \"8\"}\n{\"prediction\": 5.0, \"id\": \"9\"}\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"!wc -l /kaggle/working/predictions_dev_fixed.jsonl\n!wc -l /kaggle/input/solution-fixed/solution_fixed.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:38:48.110397Z","iopub.execute_input":"2025-11-25T03:38:48.110774Z","iopub.status.idle":"2025-11-25T03:38:48.355350Z","shell.execute_reply.started":"2025-11-25T03:38:48.110745Z","shell.execute_reply":"2025-11-25T03:38:48.353627Z"}},"outputs":[{"name":"stdout","text":"588 /kaggle/working/predictions_dev_fixed.jsonl\n588 /kaggle/input/solution-fixed/solution_fixed.jsonl\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"!head /kaggle/working/predictions_dev_fixed_with_id.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:39:08.376628Z","iopub.execute_input":"2025-11-25T03:39:08.376993Z","iopub.status.idle":"2025-11-25T03:39:08.499117Z","shell.execute_reply.started":"2025-11-25T03:39:08.376963Z","shell.execute_reply":"2025-11-25T03:39:08.497734Z"}},"outputs":[{"name":"stdout","text":"{\"prediction\": 4.0, \"id\": \"0\"}\n{\"prediction\": 3.0, \"id\": \"1\"}\n{\"prediction\": 3.0, \"id\": \"2\"}\n{\"prediction\": 4.0, \"id\": \"3\"}\n{\"prediction\": 3.0, \"id\": \"4\"}\n{\"prediction\": 3.0, \"id\": \"5\"}\n{\"prediction\": 5.0, \"id\": \"6\"}\n{\"prediction\": 3.0, \"id\": \"7\"}\n{\"prediction\": 5.0, \"id\": \"8\"}\n{\"prediction\": 5.0, \"id\": \"9\"}\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"!tail /kaggle/working/predictions_dev_fixed_with_id.jsonl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:39:23.171662Z","iopub.execute_input":"2025-11-25T03:39:23.172032Z","iopub.status.idle":"2025-11-25T03:39:23.296324Z","shell.execute_reply.started":"2025-11-25T03:39:23.172003Z","shell.execute_reply":"2025-11-25T03:39:23.295180Z"}},"outputs":[{"name":"stdout","text":"{\"prediction\": 3.0, \"id\": \"578\"}\n{\"prediction\": 3.0, \"id\": \"579\"}\n{\"prediction\": 3.0, \"id\": \"580\"}\n{\"prediction\": 3.0, \"id\": \"581\"}\n{\"prediction\": 3.0, \"id\": \"582\"}\n{\"prediction\": 3.0, \"id\": \"583\"}\n{\"prediction\": 3.0, \"id\": \"584\"}\n{\"prediction\": 3.0, \"id\": \"585\"}\n{\"prediction\": 3.0, \"id\": \"586\"}\n{\"prediction\": 3.0, \"id\": \"587\"}\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"import json\n\nbad = []\nwith open(\"/kaggle/input/solution-fixed/solution_fixed.jsonl\") as f:\n    for i, line in enumerate(f):\n        try:\n            obj = json.loads(line)\n            if \"mean\" not in obj:\n                bad.append((i, obj))\n        except:\n            bad.append((i, \"INVALID JSON\"))\n\nbad[:20], len(bad)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:41:26.801133Z","iopub.execute_input":"2025-11-25T03:41:26.801407Z","iopub.status.idle":"2025-11-25T03:41:26.813764Z","shell.execute_reply.started":"2025-11-25T03:41:26.801389Z","shell.execute_reply":"2025-11-25T03:41:26.811963Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"([], 0)"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"!python /kaggle/working/semeval26-05-scripts/scoring.py \\\n    /kaggle/input/solution-fixed/solution_fixed.jsonl \\\n    /kaggle/working/predictions_dev_fixed_with_id.jsonl \\\n    /kaggle/working/scores.json\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:41:29.389043Z","iopub.execute_input":"2025-11-25T03:41:29.389455Z","iopub.status.idle":"2025-11-25T03:41:30.231891Z","shell.execute_reply.started":"2025-11-25T03:41:29.389437Z","shell.execute_reply":"2025-11-25T03:41:30.227926Z"}},"outputs":[{"name":"stdout","text":"{'spearman': 0.3190936738480133, 'within_std_accuracy': 0.4744897959183674}\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}